{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "gcp_pdf_to_image_upload v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnishtha/Briqs/blob/master/fullworking_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMMb-W4o3k3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "1566392e-a440-4ada-e6cd-cd8653cb17d2"
      },
      "source": [
        "!pip install google-cloud-vision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-vision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/7f/e10d602c2dc3f749f1b78377a3357790f1da71b28e7da9e5bc20b3a9bd40/google_cloud_vision-1.0.0-py2.py3-none-any.whl (435kB)\n",
            "\r\u001b[K     |▊                               | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 440kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-vision) (1.16.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.52.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.17.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (47.3.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2018.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.29.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (4.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-vision) (0.4.8)\n",
            "Installing collected packages: google-cloud-vision\n",
            "Successfully installed google-cloud-vision-1.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I7AE58q3g3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4e292ce6-bff2-4956-d549-45da31243834"
      },
      "source": [
        "!apt-get install poppler-utils "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 154 kB of archives.\n",
            "After this operation, 613 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.10 [154 kB]\n",
            "Fetched 154 kB in 1s (276 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.62.0-2ubuntu2.10_amd64.deb ...\n",
            "Unpacking poppler-utils (0.62.0-2ubuntu2.10) ...\n",
            "Setting up poppler-utils (0.62.0-2ubuntu2.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-ahm-LR3xGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "199349b2-2dec-41db-8748-b43fdefa7c88"
      },
      "source": [
        "!pip install pdf2image"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/62/bf2df0547cf4e216b329a9d39a7aa6c755f02071e63e17a4b76690ebfe20/pdf2image-1.13.1-py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from pdf2image) (7.0.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lH2KAJc29LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data science codes starts here\n",
        "\n",
        "import io\n",
        "import os\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "import pandas as pd\n",
        "import json\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from dateutil import parser\n",
        "import re\n",
        "from google.cloud import storage\n",
        "from google.protobuf import json_format\n",
        "from requests.utils import requote_uri\n",
        "from urllib.request import urlopen\n",
        "from PIL import Image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N16u9Od729LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pdf2image import convert_from_bytes\n",
        "from google.cloud import storage\n",
        "import io\n",
        "import os\n",
        "from requests.utils import requote_uri\n",
        "from urllib.request import urlopen\n",
        "\n",
        "\n",
        "# pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=r'/content/drive/My Drive/briq-chronicle-8e5681b27d06.json' \n",
        "# to test the application use below script\n",
        "# print(os.environ['GOOGLE_APPLICATION_CREDENTIALS'])\n",
        "client = storage.Client()\n",
        "# C:\\Users\\Tarun Saini\\Desktop\\briqtest\\poppler-0.68.0_x86\\poppler-0.68.0\\bin\n",
        "# The os.eviron method returns a dict object of the users PATH\n",
        "\n",
        "\n",
        "\n",
        "#this function is to get the add the poppler bin path for the environment \n",
        "# def setospath():\n",
        "#     # C:\\Users\\Tarun Saini\\Desktop\\briqtest\\poppler-0.68.0_x86\\poppler-0.68.0\\bin\n",
        "#     # The os.eviron method returns a dict object of the users PATH\n",
        "#     path = os.environ['PATH']\n",
        "#     path = path + r';C:\\Users\\Tarun Saini\\Desktop\\briqtest\\poppler-0.68.0_x86\\poppler-0.68.0\\bin' # Append the path to bin as a string\n",
        "#     os.environ['PATH'] = path # Override value of 'PATH' key in the dict\n",
        "# #     print(os.environ['PATH']) # This is the new updated PATH\n",
        "# #     os.system('tarun') # Using system shell to call a program that was not on my PATH and now is\n",
        "#     return print('success')\n",
        "\n",
        "\n",
        "def getprefix(foldername,filename):\n",
        "    if filename == '':\n",
        "        customprefix= foldername+'/'\n",
        "    else:\n",
        "        customprefix= foldername + '/'+ filename\n",
        "    return customprefix\n",
        "\n",
        "\n",
        "def getfileurllisttoprocess(bucketname,foldername, filename = '', filetype= 'pdf'):\n",
        "    # how to get all files as list\n",
        "    client = storage.Client()\n",
        "    fileurllisttoprocess =[]\n",
        "    input_path_detail =[]\n",
        "    delimiter=  '/'\n",
        "    for blobnames in client.list_blobs(bucketname,delimiter = delimiter, prefix= getprefix(foldername,filename) ):\n",
        "        if (blobnames.name.lower().endswith(filetype)):\n",
        "#             print(blobnames.name)\n",
        "            input_path_url = r'https://storage.cloud.google.com/'+bucketname+'/' +blobnames.name\n",
        "            input_path_url = requote_uri(input_path_url)\n",
        "            input_path_detail.append([input_path_url,bucketname,blobnames.name, blobnames.name.split(\"/\")[-1]])\n",
        "            fileurllisttoprocess.append(input_path_detail)\n",
        "    return fileurllisttoprocess\n",
        "\n",
        "def getbufferofblog(bucketname,blobfile):\n",
        "    #print(blobfile)\n",
        "    bucket = client.get_bucket(bucketname)\n",
        "    blob = bucket.get_blob(blobfile)\n",
        "    #print(blob)\n",
        "    #print(blob.download_as_string())\n",
        "    return blob.download_as_string()\n",
        "\n",
        "\n",
        "def upload_to_bucket(imagefile,name , bucketname, imagefoldername):\n",
        "    bucket = client.get_bucket(bucketname)\n",
        "    blob = bucket.blob(getprefix(imagefoldername,name))\n",
        "    with io.BytesIO() as output:\n",
        "        imagefile.save(output, format=\"JPEG\")\n",
        "        contents = output.getvalue()\n",
        "        blob.upload_from_string(contents)\n",
        "#         blob.upload_from_string(imagefile.tobytes())\n",
        "    return print(\"i worked\")\n",
        "\n",
        "\n",
        "def fetchpdfandimagecreation(vendorid, bucketname , foldername,imagefoldername='invoice_data', filename=''):\n",
        "    #setospath()\n",
        "    listprocess =[]\n",
        "    urllist = getfileurllisttoprocess(bucketname,foldername, filename)\n",
        "    for eachpdffile in urllist:\n",
        "        inmemoryfile = getbufferofblog(eachpdffile[0][1],eachpdffile[0][2])        \n",
        "        images = convert_from_bytes(inmemoryfile)\n",
        "        for index,eachimage in enumerate(images):\n",
        "            imagename = str(vendorid)+\"__\"+eachpdffile[0][2].split('/')[-1] +'__'+str(index) +'.jpg'\n",
        "#             eachimage.save('a.jpg')\n",
        "            upload_to_bucket( eachimage,imagename,bucketname,imagefoldername)\n",
        "            listprocess.append([vendorid,eachpdffile[0][3],imagefoldername,imagename])\n",
        "    return listprocess\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x8EoS-d3HQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b03822a5-8d65-4059-fb0a-f64fa458801e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4-VMRmY29LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "input -> folder path in which images and config yaml file is stored\n",
        "output-> will extract all info's of field that are mention in yaml file\n",
        "\"\"\"\n",
        "def get_invoice_data_v1(configjson, image):\n",
        "    # if imagefiles==None:\n",
        "    #   files = list(set(os.listdir(path))-set([jsonfile]))\n",
        "    # else:\n",
        "    #   files = [path+imagefile for imagefile in imagefiles]\n",
        "    #print(files)\n",
        "    data = []\n",
        "    t=[]\n",
        "    # for file in files:\n",
        "    mapping = configjson\n",
        "    #print(mapping)\n",
        "    temp_df = detect_text_v1(image)\n",
        "    #print(temp_df)\n",
        "    tmp_dict = {}\n",
        "    inTableMapping={}\n",
        "    for k in mapping.keys():\n",
        "        #print(k)\n",
        "        if mapping[k]['isTable'] == 'True' and  mapping[k]['moveable'] == 'False' :\n",
        "            #print(k)\n",
        "            mapping[k].pop('moveable')\n",
        "            mapping[k].pop('isTable')\n",
        "            tmp_dict[k] = get_table_structure_data(get_sequence_data(temp_df),mapping[k],False)\n",
        "        elif mapping[k]['isTable'] == 'True' and  mapping[k]['moveable'] == 'True' :\n",
        "            mapping[k].pop('moveable')\n",
        "            mapping[k].pop('isTable')\n",
        "            tmp_dict[k] = get_table_structure_data(get_sequence_data(temp_df),mapping[k],True)\n",
        "        elif mapping[k]['isTable'] == 'False' and  mapping[k]['moveable'] == 'False' :\n",
        "            #print(k)\n",
        "            #mapping[k].pop('moveable')\n",
        "            #mapping[k].pop('isTable')\n",
        "            filter_data = temp_df[(mapping[k]['x0'] < temp_df['centerx']) & (temp_df['centerx'] < mapping[k]['x1']) & (mapping[k]['y0'] < temp_df['centery']) & (temp_df['centery'] < mapping[k]['y1'])].sort_values(by='x0')\n",
        "            tmp_dict[k] = data_format((\" \").join(get_sequence_data(filter_data)['text']),mapping[k][\"type\"])\n",
        "        elif mapping[k]['isTable'] == 'False' and  mapping[k]['moveable'] == 'True' :\n",
        "            #print(k)\n",
        "            tmp_dict[k] = get_moveable_field_data(get_sequence_data(temp_df),mapping[k],False)\n",
        "        #print(tmp_dict)\n",
        "    data.append(tmp_dict)\n",
        "    return data"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kbp3Rw829LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_text_v1(content):\n",
        "    \"\"\"Detects text in the file. Using google vision api (output will be in dataframe format)\"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "\n",
        "    # with io.open(path, 'rb') as image_file:\n",
        "    #     content = image_file.read()\n",
        "\n",
        "    image = vision.types.Image(content=content)\n",
        "\n",
        "    response = client.text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    txt = []\n",
        "    x0 = []\n",
        "    x1 = []\n",
        "    y0 = []\n",
        "    y1 = []\n",
        "    centerx = []\n",
        "    centery = []\n",
        "    for text in texts[1:]:\n",
        "        #print('\\n\"{}\"'.format(text.description))\n",
        "        txt.append(text.description)\n",
        "        vertices = ([(vertex.x, vertex.y)\n",
        "                    for vertex in text.bounding_poly.vertices])\n",
        "        x0.append(vertices[0][0]) \n",
        "        x1.append(vertices[1][0])\n",
        "        y0.append(vertices[0][1])\n",
        "        y1.append(vertices[2][1])\n",
        "        centerx.append(int((vertices[0][0]+vertices[1][0])/2))\n",
        "        centery.append(int((vertices[0][1]+vertices[2][1])/2))\n",
        "        #print('bounds: ',(vertices))\n",
        "    return pd.DataFrame({\"text\":txt,\"x0\":x0,\"y0\":y0,\"x1\":x1,\"y1\":y1,\"centerx\":centerx,\"centery\":centery})\n",
        "    if response.error.message:\n",
        "        raise Exception(\n",
        "            '{}\\nFor more info on error messages, check: '\n",
        "            'https://cloud.google.com/apis/design/errors'.format(\n",
        "                response.error.message))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fT_7_Rn29Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Take dataframe as input and add column line for each words  \"\"\"\n",
        "def get_sequence_data(data):\n",
        "    df = data.sort_values(by = [\"centery\"])\n",
        "    lst = list(df['centery'])\n",
        "    count = 0\n",
        "    line = []\n",
        "    for i in range(len(lst)):\n",
        "        if i != len(lst)-1:\n",
        "            if lst[i+1] - lst[i] > 8:\n",
        "                line.append(count)\n",
        "                count += 1\n",
        "            else:\n",
        "                line.append(count)\n",
        "        else:\n",
        "            line.append(count)\n",
        "    df['line'] = line\n",
        "    df = df.sort_values(by=['line','x0'])\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    #print(\"xxx\")\n",
        "    #print(df)\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ZoXdNL29Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "input -> start_text of and end_text of field\n",
        "output -> return info of field (for moveable data)\n",
        "\"\"\"\n",
        "def get_moveable_field_data(data,key,isTable):\n",
        "    start_data = data[data['text'].astype(str).str.contains(key['start'], case=False)]\n",
        "    end_data = data[data['text'].astype(str).str.contains(key['end'], case=False)]\n",
        "    temp_dct = {}\n",
        "    for ind, row in start_data.iterrows():\n",
        "        temp_dct[str(ind)+\"_\"+str(abs(end_data['line'] - row['line']).idxmin())] = min(abs(end_data['line'] - row['line']))\n",
        "    indxs = min(temp_dct, key=temp_dct.get)\n",
        "    strt = int(indxs.split(\"_\")[0])\n",
        "    end = int(indxs.split(\"_\")[1])\n",
        "    end_line = data.loc[end,'line']\n",
        "    strt_line = data.loc[strt,'line']\n",
        "    if isTable==False:\n",
        "        if end_line != strt_line:\n",
        "            return data_format((\" \").join(data[(data.loc[strt,'x1'] < data['x0']) & (strt_line == data['line'])]['text']),key['type'])\n",
        "        else:\n",
        "            return data_format((\" \").join(data[(data.loc[strt,'x1'] < data['x0']) & (data.loc[end,'x0'] > data['x1'])  & (strt_line == data['line'])]['text']),key[\"type\"])\n",
        "    # else:\n",
        "    #     #print(key)\n",
        "    #     return get_table_structure_data(data[(end_line > data['line']) & (strt_line <= data['line'])],key,True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97OXR_tS29L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convert the types of info field as given in yaml file\n",
        "\"\"\"\n",
        "def data_format(x,frmt):\n",
        "    try:\n",
        "        if frmt == \"float\":\n",
        "            return float(x)\n",
        "        elif frmt == \"int\":\n",
        "            return int(x) \n",
        "        elif frmt == 'date':\n",
        "            return parser.parse(x).isoformat()\n",
        "        else:\n",
        "            return str(x)  \n",
        "    except:\n",
        "        return str(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnntTrvS29MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "return key which has particular value (used in Pipline_for_get_complete_row function)\n",
        "\"\"\"\n",
        "def get_key(my_dict,val): \n",
        "    for key, value in my_dict.items(): \n",
        "        if val == value: \n",
        "            return key "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHIYCWz329ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function is use to convert fetched table as given in images \n",
        "\"\"\"\n",
        "def get_complete_row(df,key):\n",
        "    restructure_data = {new_list: [] for new_list in df.columns}\n",
        "    for index,row in df.iterrows():\n",
        "        try:\n",
        "            if row[key] != \"\":\n",
        "                for i in df.columns:\n",
        "                    restructure_data[i].append(row[i])\n",
        "            else:\n",
        "                for i in df.columns:\n",
        "                    restructure_data[i] = restructure_data[i][:-1] + [restructure_data[i][-1] + row[i]]\n",
        "        except:\n",
        "            pass\n",
        "    return restructure_data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDXBAyzF29MI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "input -> raw table data (unformatted)\n",
        "output -> same format tabe as in image\n",
        "function use-> get_key(), get_complete_row()\n",
        "\"\"\"\n",
        "def Pipline_for_get_complete_row(table_data):\n",
        "    df = pd.DataFrame(table_data)\n",
        "    tmp = {new_list: len(list(filter(lambda x: x != \"\", df[new_list]))) for new_list in df.columns}\n",
        "    val = Counter(list(tmp.values())).most_common(1)[0][0]\n",
        "    key = get_key(tmp,val)\n",
        "    updated_table_data = get_complete_row(df,key)\n",
        "    return updated_table_data"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19wFq5vP29MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function takes google vision data, and extract the table data (unformatted)\n",
        "\"\"\"\n",
        "def get_table_structure_data(data,key,moveable_flag):\n",
        "    if moveable_flag == True:\n",
        "        df = data\n",
        "    else:\n",
        "        #print(data)\n",
        "        index = data.loc[data[data['text'].astype(str).str.contains(key['end'], case=False) & (data['y0'] > key['y0'])].index.values[0],'line']\n",
        "        df = data[(key['x0'] < data['centerx']) & (data['centerx'] < key['x1']) & (key['y0'] < data['centery']) & (data['line'] < index)]\n",
        "    #print(df,\"-->\",data[data['text'].str.contains(key['end'], case=False) & (data['y0'] > key['y0'])],index)\n",
        "    key_list = list(set(list(key.keys()))-set(['x0','x1','y0','end','start']))\n",
        "    table_data = {new_list: [] for new_list in key_list}\n",
        "    #print(df) \n",
        "    for i in key_list:\n",
        "        #print(i)\n",
        "        flag = False\n",
        "        for k in list(set(list(df['line']))):\n",
        "            temp_df = df[(df['line']==k) & (key[i]['x0'] < df['centerx']) & (key[i]['x1'] > df['centerx'])]\n",
        "            if flag:\n",
        "                #print(key[i][\"type\"])\n",
        "                table_data[i].append((\" \").join(temp_df['text']))\n",
        "            flag = True\n",
        "    structure_table = Pipline_for_get_complete_row(table_data)\n",
        "    type_mapping = {i:key[i]['type'] for i in key.keys() if type(key[i]) == dict}\n",
        "    updated_structure_table = {i:[data_format(x,type_mapping[i]) for x in structure_table[i]] for i in structure_table.keys()}\n",
        "    return updated_structure_table"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujKEVo9F29MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#these are the inputs\n",
        "#lets start with the code of image processing with frebase functions\n",
        "#this data will come form the fire base\n",
        "\n",
        "mapping= {\n",
        "  \"Address\": {\n",
        "    \"x0\": 230,\n",
        "    \"x1\": 820,\n",
        "    \"y0\": 100,\n",
        "    \"y1\": 240,\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"False\",\n",
        "    \"type\": \"str\"\n",
        "  },\n",
        "  \"Invoice Number\": {\n",
        "    \"x0\": 1440,\n",
        "    \"x1\": 1650,\n",
        "    \"y0\": 230,\n",
        "    \"y1\": 300,\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"False\",\n",
        "    \"type\": \"int\"\n",
        "  },\n",
        "  \"Invoive Date\": {\n",
        "    \"x0\": 1230,\n",
        "    \"x1\": 1440,\n",
        "    \"y0\": 230,\n",
        "    \"y1\": 300,\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"False\",\n",
        "    \"type\": \"date\"\n",
        "  },\n",
        "  \"BILL to\": {\n",
        "    \"x0\": 150,\n",
        "    \"x1\": 830,\n",
        "    \"y0\": 430,\n",
        "    \"y1\": 700,\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"False\",\n",
        "    \"type\": \"str\"\n",
        "  },\n",
        "  \"job site\": {\n",
        "    \"x0\": 910,\n",
        "    \"x1\": 1600,\n",
        "    \"y0\": 430,\n",
        "    \"y1\": 700,\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"False\",\n",
        "    \"type\": \"str\"\n",
        "  },\n",
        "  \"total\": {\n",
        "    \"x0\": 1340,\n",
        "    \"x1\": 1620,\n",
        "    \"y0\": 970,\n",
        "    \"y1\": 2030,\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"False\",\n",
        "    \"type\": \"int\"\n",
        "  },\n",
        "  \"table\": {\n",
        "    \"x0\": 100,\n",
        "    \"x1\": 1630,\n",
        "    \"y0\": 880,\n",
        "    \"end\": \"total\",\n",
        "    \"moveable\": \"False\",\n",
        "    \"isTable\": \"True\",\n",
        "    \"date\": {\n",
        "      \"x0\": 100,\n",
        "      \"x1\": 300,\n",
        "      \"type\": \"date\"\n",
        "    },\n",
        "    \"Ticket\": {\n",
        "      \"x0\": 300,\n",
        "      \"x1\": 420,\n",
        "      \"type\": \"str\"\n",
        "    },\n",
        "    \"quantity\": {\n",
        "      \"x0\": 420,\n",
        "      \"x1\": 545,\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    \"comments\": {\n",
        "      \"x0\": 545,\n",
        "      \"x1\": 975,\n",
        "      \"type\": \"str\"\n",
        "    },\n",
        "    \"description\": {\n",
        "      \"x0\": 975,\n",
        "      \"x1\": 1300,\n",
        "      \"type\": \"str\"\n",
        "    },\n",
        "    \"price each\": {\n",
        "      \"x0\": 1300,\n",
        "      \"x1\": 1470,\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    \"amount\": {\n",
        "      \"x0\": 1470,\n",
        "      \"x1\": 1630,\n",
        "      \"type\": \"int\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "firebaseoutput = { 'is_process':'completed' ,\"bounds\": mapping}\n",
        "\n",
        "\n",
        "#once all images are converted \n",
        "# vendorid, bucketname , foldername,imagefoldername, filename\n",
        "vendorid1 = 12\n",
        "bucketname1 = 'auto-invoicing-dev'\n",
        "foldername1 = 'invoice_test'\n",
        "imagefoldername1='invoice_data'\n",
        "filename1 = 'Inv_38449_from_Excel_Disposal_LLC_8496.pdf'"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T11bwZvM29MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mainfunction(vendorid,bucketname,foldername,imagefoldername,filename, firebaseoutput):\n",
        "    #request for getting images generated and uplaoded into the google storage\n",
        "    #then getting the list of all images uploaded in the request\n",
        "    listofimagestobeprocessed= fetchpdfandimagecreation(vendorid, bucketname , foldername,imagefoldername, filename)\n",
        "    for eachimage in listofimagestobeprocessed:\n",
        "        #call the cofig file json from firebase and save as firebaseoutput json based on image\n",
        "        #firebaseoutput= functionname(imput vendor id hitting firebase index of google bounds)\n",
        "#         print(getprefix(eachimage[2],eachimage[3]))\n",
        "        imageasstring = getbufferofblog(bucketname, getprefix(eachimage[2],eachimage[3]))\n",
        "        #return len(imageasstring)\n",
        "#         get_invoice_data_v1(firebaseoutput['bounds'],imageasstring)  \n",
        "\n",
        "    return print(get_invoice_data_v1(firebaseoutput['bounds'],imageasstring))\n",
        "# mainfunction(\"12\",bucketname1,foldername1,imagefoldername1,filename1)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QPdT0jXd29MY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dbcc58a5-5a40-454c-89a4-5c381e951d60"
      },
      "source": [
        "mainfunction(\"12\",bucketname1,foldername1,imagefoldername1,filename1, firebaseoutput)\n",
        "#bucketname is the parent bucket where all folders are located\n",
        "#foldername1 is the folder location where our file is present in the google bucket\n",
        "#imagefoldername1 is the folder where code will push the converted images. default : invoice_data\n",
        "#filename1 is optional if leaved as \"\" blank it will get all pdf located in the folder and fect\n",
        "#firebaseoutput  variable need to be fetched from the \"google_bounds\" index \n",
        "#output of the main function will be passed to firebase \"google extracted text\""
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i worked\n",
            "[{'Address': 'Excel Disposal, LLC 5817 46th St. Kenosha, WI 53144', 'Invoice Number': 38449, 'Invoive Date': '2019-09-11T00:00:00', 'BILL to': 'Berglund Construction 8410 S. South Chicago Ave Chicago, IL 60617', 'job site': '5001 Simmons Island rd Kenosha, WI', 'total': '20.00 20.00 $390.00', 'table': {'comments': ['', ''], 'date': ['2019-09-05T00:00:00', ''], 'amount': ['370.00', '20.00'], 'Ticket': ['', ''], 'quantity': [1, 1], 'description': ['12yd GD Delivery', 'Dot Regulations Fee'], 'price each': ['370.00', '20.00']}}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv6nrEEQ29Md",
        "colab_type": "code",
        "colab": {},
        "outputId": "f82936a3-a594-4ee1-9ff6-76af143bb41e"
      },
      "source": [
        "print('''json output of the get_invoice_data_v1(firebaseoutput['bounds'],imageasstring) is coming 3 time where as it was only called once''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "json output of the get_invoice_data_v1(firebaseoutput['bounds'],imageasstring) is coming 3 time where as it was only called once\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}